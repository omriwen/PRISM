{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SPIDS Web Dashboard Tutorial\n",
    "\n",
    "Learn how to use the interactive web dashboard for real-time training monitoring and multi-experiment comparison.\n",
    "\n",
    "This tutorial covers:\n",
    "1. Launching the dashboard\n",
    "2. Monitoring training in real-time\n",
    "3. Comparing multiple experiments\n",
    "4. Interactive visualizations\n",
    "5. Configuration comparison\n",
    "\n",
    "**Estimated time**: 20-25 minutes\n",
    "\n",
    "**Requirements**: \n",
    "- Dash and dash-bootstrap-components installed (included in `uv sync`)\n",
    "- At least one completed experiment in `runs/` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "# SPIDS imports\n",
    "from prism.web.launcher import DashboardLauncher\n",
    "from prism.web.server import DashboardServer\n",
    "\n",
    "\n",
    "# Check available experiments\n",
    "runs_dir = Path(\"../../runs\")\n",
    "experiments = list(runs_dir.glob(\"*/checkpoint.pt\"))\n",
    "\n",
    "print(f\"✓ Found {len(experiments)} experiments in runs/\")\n",
    "if len(experiments) > 0:\n",
    "    print(\"\\nAvailable experiments:\")\n",
    "    for exp in experiments[:5]:  # Show first 5\n",
    "        print(f\"  - {exp.parent.name}\")\n",
    "    if len(experiments) > 5:\n",
    "        print(f\"  ... and {len(experiments) - 5} more\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No experiments found. Run a training first:\")\n",
    "    print(\"     cd ../.. && uv run python main.py --obj_name europa --n_samples 64 --max_epochs 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dashboard-features",
   "metadata": {},
   "source": [
    "## 2. Dashboard Features Overview\n",
    "\n",
    "The SPIDS dashboard provides:\n",
    "\n",
    "### Real-Time Monitoring\n",
    "- Live training progress updates\n",
    "- Interactive Plotly charts (zoom, pan, hover)\n",
    "- Current epoch, loss, SSIM, PSNR metrics\n",
    "- Reconstruction preview vs ground truth\n",
    "\n",
    "### Multi-Experiment Comparison\n",
    "- Select and compare up to 4 experiments\n",
    "- Side-by-side visualization\n",
    "- Training curves overlay\n",
    "- Configuration differences\n",
    "\n",
    "### Interactive Visualizations\n",
    "- K-space coverage heatmaps\n",
    "- Sampling pattern visualization\n",
    "- Synchronized zoom/pan\n",
    "- Export plots as PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "launch-dashboard",
   "metadata": {},
   "source": [
    "## 3. Launching the Dashboard\n",
    "\n",
    "### Method 1: From Command Line (Recommended)\n",
    "\n",
    "The simplest way to launch the dashboard:\n",
    "\n",
    "```bash\n",
    "cd ../..\n",
    "spids dashboard --port 8050\n",
    "```\n",
    "\n",
    "Then open your browser to: http://localhost:8050\n",
    "\n",
    "### Method 2: During Training\n",
    "\n",
    "Launch dashboard alongside training:\n",
    "\n",
    "```bash\n",
    "cd ../..\n",
    "python main.py --obj_name europa --n_samples 100 --dashboard\n",
    "```\n",
    "\n",
    "### Method 3: Programmatically (This Notebook)\n",
    "\n",
    "Launch from Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "launch-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch dashboard in background\n",
    "launcher = DashboardLauncher(port=8050)\n",
    "\n",
    "print(\"Starting dashboard...\")\n",
    "launcher.start()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dashboard is running!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nOpen in your browser: http://localhost:8050\")\n",
    "print(\"\\nPress Ctrl+C in the terminal to stop the dashboard.\")\n",
    "print(\"\\nTo stop from this notebook, run: launcher.stop()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dashboard-ui",
   "metadata": {},
   "source": [
    "## 4. Dashboard User Interface\n",
    "\n",
    "### Main Components:\n",
    "\n",
    "1. **Sidebar (Left)**\n",
    "   - Experiment selector (dropdown with multi-select)\n",
    "   - Refresh rate slider (1-10 seconds)\n",
    "   - Quick actions\n",
    "\n",
    "2. **Main Content (Right)**\n",
    "   - Tabs: Training Metrics | Reconstructions | K-Space | Configuration\n",
    "   - Interactive plots\n",
    "   - Real-time updates\n",
    "\n",
    "3. **Navigation Bar (Top)**\n",
    "   - SPIDS branding\n",
    "   - Current status indicator\n",
    "\n",
    "### Navigation Tips:\n",
    "- **Select experiments**: Use dropdown to choose 1-4 experiments\n",
    "- **Zoom**: Click and drag on plots\n",
    "- **Pan**: Hold Shift and drag\n",
    "- **Hover**: Mouse over data points for details\n",
    "- **Reset view**: Double-click on plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-data",
   "metadata": {},
   "source": [
    "## 5. Exploring Experiment Data\n",
    "\n",
    "Let's load and explore experiment data programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dashboard server\n",
    "server = DashboardServer(runs_dir=Path(\"../../runs\"))\n",
    "\n",
    "# Scan for experiments\n",
    "available_exps = server.scan_experiments()\n",
    "\n",
    "print(f\"Found {len(available_exps)} experiments:\\n\")\n",
    "for exp in available_exps[:5]:\n",
    "    print(f\"ID: {exp['id']}\")\n",
    "    print(f\"  Path: {exp['path']}\")\n",
    "    print(f\"  Last modified: {time.ctime(exp['last_modified'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-single-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for a specific experiment\n",
    "if len(available_exps) > 0:\n",
    "    exp_id = available_exps[0][\"id\"]\n",
    "    exp_data = server.load_experiment_data(exp_id)\n",
    "\n",
    "    print(f\"Loaded experiment: {exp_id}\\n\")\n",
    "    print(\"Metrics:\")\n",
    "    for key, value in exp_data[\"metrics\"].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(\"\\nConfiguration highlights:\")\n",
    "    config = exp_data[\"config\"]\n",
    "    if \"obj_name\" in config:\n",
    "        print(f\"  Object: {config['obj_name']}\")\n",
    "    if \"n_samples\" in config:\n",
    "        print(f\"  Samples: {config['n_samples']}\")\n",
    "    if \"pattern_type\" in config:\n",
    "        print(f\"  Pattern: {config['pattern_type']}\")\n",
    "else:\n",
    "    print(\"No experiments available to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-workflow",
   "metadata": {},
   "source": [
    "## 6. Multi-Experiment Comparison Workflow\n",
    "\n",
    "### In the Dashboard:\n",
    "\n",
    "1. **Select experiments**: In the sidebar dropdown, select 2-4 experiments\n",
    "2. **View Training tab**: See overlaid training curves\n",
    "3. **View Reconstructions tab**: Side-by-side comparison\n",
    "4. **View Configuration tab**: See parameter differences\n",
    "\n",
    "### Key Questions to Answer:\n",
    "\n",
    "- Which configuration achieved the best metrics?\n",
    "- How does training time compare?\n",
    "- What parameters differ between experiments?\n",
    "- Which sampling pattern works best?\n",
    "- How does convergence behavior differ?\n",
    "\n",
    "### Example Comparison Scenarios:\n",
    "\n",
    "**Scenario 1: Pattern Comparison**\n",
    "- Select experiments with different sampling patterns (fermat, random, star)\n",
    "- Compare final SSIM values\n",
    "- Observe convergence speed\n",
    "\n",
    "**Scenario 2: Sample Count Study**\n",
    "- Select experiments with 50, 100, 150, 200 samples\n",
    "- See quality vs efficiency tradeoff\n",
    "- Identify optimal sample count\n",
    "\n",
    "**Scenario 3: Hyperparameter Tuning**\n",
    "- Compare learning rates (0.001, 0.005, 0.01)\n",
    "- Compare batch sizes\n",
    "- Compare optimizer choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive-features",
   "metadata": {},
   "source": [
    "## 7. Interactive Features Demo\n",
    "\n",
    "### Training Curves\n",
    "- **Zoom**: Focus on convergence region\n",
    "- **Toggle lines**: Click legend entries to show/hide\n",
    "- **Smoothing**: Adjust slider to smooth noisy curves\n",
    "- **Export**: Camera icon to save as PNG\n",
    "\n",
    "### Reconstructions\n",
    "- **Colormap**: Change color scheme\n",
    "- **Zoom**: Examine fine details\n",
    "- **Toggle views**: Switch between magnitude/phase\n",
    "\n",
    "### K-Space Coverage\n",
    "- **Heatmap**: See sampling density\n",
    "- **Radial profile**: Plot coverage vs frequency\n",
    "- **Pattern overlay**: Show sampling positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realtime-monitoring",
   "metadata": {},
   "source": [
    "## 8. Real-Time Monitoring During Training\n",
    "\n",
    "When training with `--dashboard` flag:\n",
    "\n",
    "```bash\n",
    "python main.py --obj_name europa --n_samples 100 --dashboard\n",
    "```\n",
    "\n",
    "The dashboard will:\n",
    "1. Auto-refresh every 2 seconds (configurable)\n",
    "2. Show current epoch and progress\n",
    "3. Update training curves in real-time\n",
    "4. Display latest reconstruction\n",
    "5. Show ETA and elapsed time\n",
    "\n",
    "### Real-Time Features:\n",
    "- **Live metrics**: Loss, SSIM, PSNR updated continuously\n",
    "- **Progress indicator**: Visual progress bar\n",
    "- **Current reconstruction**: See latest output\n",
    "- **Training speed**: Iterations per second\n",
    "- **Memory usage**: GPU/CPU memory stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configuration-comparison",
   "metadata": {},
   "source": [
    "## 9. Configuration Comparison\n",
    "\n",
    "The Configuration tab shows:\n",
    "\n",
    "### Parameter Diff Table\n",
    "- **Green**: Parameters that improved results\n",
    "- **Red**: Parameters that worsened results\n",
    "- **Gray**: Neutral parameters\n",
    "\n",
    "### Comparison Insights\n",
    "- Which parameters have the most impact?\n",
    "- Are there consistent patterns?\n",
    "- What's the sensitivity to each parameter?\n",
    "\n",
    "### Example Analysis:\n",
    "```\n",
    "Parameter       Exp1    Exp2    Exp3    Impact\n",
    "─────────────────────────────────────────────\n",
    "n_samples       50      100     150     HIGH\n",
    "learning_rate   0.001   0.001   0.005   LOW\n",
    "pattern         fermat  random  fermat  MEDIUM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tips-tricks",
   "metadata": {},
   "source": [
    "## 10. Tips and Tricks\n",
    "\n",
    "### Performance Tips:\n",
    "1. **Limit experiments**: Compare max 4 at once for responsiveness\n",
    "2. **Adjust refresh rate**: Slower rate = less CPU usage\n",
    "3. **Close unused tabs**: Reduces rendering overhead\n",
    "\n",
    "### Visualization Tips:\n",
    "1. **Use log scale**: For loss curves with large dynamic range\n",
    "2. **Normalize metrics**: Compare experiments at different scales\n",
    "3. **Export plots**: Use camera icon for presentations\n",
    "\n",
    "### Workflow Tips:\n",
    "1. **Bookmark experiments**: Save interesting ones for later\n",
    "2. **Take screenshots**: Document interesting findings\n",
    "3. **Use multiple tabs**: Compare different aspects simultaneously\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Dashboard not loading**: Check port 8050 is not in use\n",
    "- **No data showing**: Verify experiments have checkpoints\n",
    "- **Slow updates**: Reduce refresh rate or number of experiments\n",
    "- **Memory issues**: Close other applications, limit experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stop-dashboard",
   "metadata": {},
   "source": [
    "## 11. Stopping the Dashboard\n",
    "\n",
    "To stop the dashboard launched from this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stop-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop dashboard\n",
    "try:\n",
    "    launcher.stop()\n",
    "    print(\"✓ Dashboard stopped successfully\")\n",
    "except Exception:\n",
    "    print(\"⚠️  No dashboard running or already stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## 12. Next Steps\n",
    "\n",
    "### Explore More:\n",
    "- Try comparing experiments with different patterns\n",
    "- Monitor a long training run in real-time\n",
    "- Export interesting plots for presentations\n",
    "- Identify optimal hyperparameters\n",
    "\n",
    "### Related Tools:\n",
    "- **Compare CLI**: `spids compare runs/exp1 runs/exp2` - Terminal comparison\n",
    "- **Inspect CLI**: `spids inspect runs/exp/checkpoint.pt` - Detailed inspection\n",
    "- **Report Generation**: See Tutorial 5 for automated reports\n",
    "\n",
    "### Advanced Usage:\n",
    "- Custom dashboard layouts\n",
    "- Remote dashboard access (SSH tunneling)\n",
    "- Dashboard API for automation\n",
    "- Integration with Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ✓ How to launch the SPIDS dashboard\n",
    "- ✓ Real-time training monitoring\n",
    "- ✓ Multi-experiment comparison\n",
    "- ✓ Interactive visualizations\n",
    "- ✓ Configuration analysis\n",
    "\n",
    "**Next tutorial**: Tutorial 5: Automatic Report Generation\n",
    "\n",
    "---\n",
    "\n",
    "**Resources**:\n",
    "- [Dashboard Documentation](../../docs/UI_UX_UPGRADE_PLAN.md#phase-2-interactive-web-dashboard)\n",
    "- [API Reference](../../docs/user_guide.md)\n",
    "- [GitHub Issues](https://github.com/username/SPIDS/issues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
